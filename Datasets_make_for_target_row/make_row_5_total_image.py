#test() í•¨ìˆ˜ê°€ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•´ì„œ â†’ ìµœì¢…ì ìœ¼ë¡œ evaluate_SNet()ì„ í˜¸ì¶œí•˜ê³ , ì—¬ê¸°ì„œ ëª¨ë¸ forwardì™€ ë©”íŠ¸ë¦­ ê³„ì‚°/ì‹œê°í™”ë¥¼ ì „ë¶€ ìˆ˜í–‰í•˜ëŠ” êµ¬ì¡°.
# output: ë§¤ì¹­ ê²°ê³¼ ì‚¬ì§„ + matrix

import numpy as np
import os
import torch
import argparse
from model.network import STHN
from utils import save_overlap_img, save_img, setup_seed, save_overlap_bbox_img
import datasets_4cor_img as datasets
import scipy.io as io
import torchvision
import numpy as np
import time
from tqdm import tqdm
import cv2
import kornia.geometry.transform as tgm
import matplotlib.pyplot as plt
from plot_hist import plot_hist_helper
import torch.nn.functional as F
import parser
from datetime import datetime
from os.path import join
import commons
import logging
import wandb
import platform

#í…ŒìŠ¤íŠ¸/ ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê°€ ìˆ˜í–‰ í•¨ìˆ˜ 
def test(args, wandb_log):
    if not args.identity:
        model = STHN(args)

        # ---- checkpoint load ----
        model_med = torch.load(args.eval_model, map_location='cuda:0')
        for key in list(model_med['netG'].keys()):
            model_med['netG'][key.replace('module.', '')] = model_med['netG'][key]
        for key in list(model_med['netG'].keys()):
            if key.startswith('module'):
                del model_med['netG'][key]
        model.netG.load_state_dict(model_med['netG'], strict=False)

        if args.two_stages:
            model_med = torch.load(args.eval_model, map_location='cuda:0')
            for key in list(model_med['netG_fine'].keys()):
                model_med['netG_fine'][key.replace('module.', '')] = model_med['netG_fine'][key]
            for key in list(model_med['netG_fine'].keys()):
                if key.startswith('module'):
                    del model_med['netG_fine'][key]
            model.netG_fine.load_state_dict(model_med['netG_fine'])

        model.setup()
        model.netG.eval()
        if args.two_stages:
            model.netG_fine.eval()
    else:
        model = None

    if args.test:
        val_dataset = datasets.fetch_dataloader(args, split='test')
    else:
        val_dataset = datasets.fetch_dataloader(args, split='val')

    evaluate_SNet(model, val_dataset, batch_size=args.batch_size, args=args, wandb_log=wandb_log)



def evaluate_SNet(model, val_dataset, batch_size=0, args=None, wandb_log=False):
    """
    ëª¨ë¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜
    - ë°°ì¹˜ë³„ë¡œ forward pass ìˆ˜í–‰
    - MACE, CE ë“±ì˜ ë©”íŠ¸ë¦­ ê³„ì‚°
    - ë§¤ì¹­ ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
    """
    assert batch_size > 0, "batchsize > 0"

    # ë³€ìˆ˜ ì •ë¦¬ 
    # ë©”íŠ¸ë¦­ ëˆ„ì ìš© í…ì„œ ì´ˆê¸°í™”
    total_mace = torch.empty(0)  # Mean Average Corner Error
    total_flow = torch.empty(0)  # Ground Truth Flow í¬ê¸°
    total_ce = torch.empty(0)  # Center Error
    total_mace_conf_error = torch.empty(0)  # Uncertainty ê´€ë ¨ ì—ëŸ¬

    # âœ… ì´ ë¶€ë¶„ ì¶”ê°€
    final_mace = 0.0
    final_ce = 0.0
    final_flow = 0.0
    final_mace_conf_error = 0.0

    timeall = []
    mace_conf_list = []

    # Recall@1ì„ ìœ„í•œ ë³€ìˆ˜ë“¤ ì¶”ê°€
    correct_predictions_25 = 0
    total_predictions_25 = 0
    correct_predictions_10 = 0
    total_predictions_10 = 0
    correct_predictions_1= 0
    total_predictions_1= 0

    # ==================== ì‹œê°í™” ë²”ìœ„ ì„¤ì • ====================
    VIS_START_INDEX = 0      # ì‹œì‘ ì¸ë±ìŠ¤ (ì´ ê°’ë¶€í„° ì €ì¥)
    VIS_END_INDEX = None     # ë ì¸ë±ìŠ¤ (Noneì´ë©´ ëê¹Œì§€, ìˆ«ìë©´ í•´ë‹¹ ì¸ë±ìŠ¤ ì „ê¹Œì§€)
    # ì˜ˆì‹œ: VIS_START_INDEX = 100, VIS_END_INDEX = 200 â†’ 100ë²ˆë¶€í„° 199ë²ˆê¹Œì§€ ì €ì¥
    # ì˜ˆì‹œ: VIS_START_INDEX = 0, VIS_END_INDEX = None â†’ ì „ì²´ ì €ì¥
    
    saved_vis_count = 0     # ì €ì¥ëœ ì‹œê°í™” ê°œìˆ˜

    # ìƒ˜í”Œ ê°œìˆ˜ë¡œ ì œí•œ
    MAX_EVAL_SAMPLES = 2200  # None = ì „ì²´ í‰ê°€, ìˆ«ì ì§€ì • ì‹œ í•´ë‹¹ ê°œìˆ˜ë§Œ í‰ê°€
    processed_samples = 0   # ì²˜ë¦¬ëœ ìƒ˜í”Œ ì¹´ìš´í„°
    # ==================== 

    if args.generate_test_pairs:
        test_pairs = torch.zeros(len(val_dataset.dataset), dtype=torch.long)

    # GPU ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
    torch.cuda.empty_cache()

    # ë°°ì¹˜ë³„ í‰ê°€ ë£¨í”„
    for i_batch, data_blob in enumerate(tqdm(val_dataset)):
        # ìƒ˜í”Œ ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì¡°ê¸° ì¢…ë£Œ (MAX_EVAL_SAMPLESê°€ Noneì´ ì•„ë‹ ë•Œë§Œ)
        if MAX_EVAL_SAMPLES is not None and processed_samples >= MAX_EVAL_SAMPLES:
            break

        # ë°ì´í„° ì–¸íŒ©
        img1, img2, flow_gt, H, query_utm, database_utm, index, pos_index = [x for x in data_blob]
        current_batch_size = img1.shape[0]  # í˜„ì¬ ë°°ì¹˜ì˜ ì‹¤ì œ ìƒ˜í”Œ ìˆ˜

        if args.generate_test_pairs:
            test_pairs[index] = pos_index

        # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ì¬í˜„ì„± í™•ì¸ìš© ë¡œê·¸ ì¶œë ¥
        """
        if i_batch == 0:
            logging.info("Check the reproducibility by UTM:")
            logging.info(f"the first 5th query UTMs: {query_utm[:5]}")
            logging.info(f"the first 5th database UTMs: {database_utm[:5]}")
        """

        # 1000 ë°°ì¹˜ë§ˆë‹¤ ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥
        if i_batch % 1000 == 0:
            save_img(torchvision.utils.make_grid((img1)),
                     args.save_dir + "/b1_epoch_" + str(i_batch).zfill(5) + "_finaleval_" + '.png')
            save_img(torchvision.utils.make_grid((img2)),
                     args.save_dir + "/b2_epoch_" + str(i_batch).zfill(5) + "_finaleval_" + '.png')
            torch.cuda.empty_cache()

        if not args.identity:
            # ëª¨ë¸ì— ì…ë ¥ ì„¤ì •
            model.set_input(img1, img2, flow_gt)

        # ==================== ëª¨ë¸ Forward Pass & ë©”íŠ¸ë¦­ ê³„ì‚° ====================
        if args.train_ue_method != 'train_only_ue_raw_input':
            if not args.identity:
                # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (í‰ê°€ ëª¨ë“œ, ë©”ëª¨ë¦¬ ì ˆì•½)
                with torch.no_grad():
                    model.forward()
                four_pred = model.four_pred  # ì˜ˆì¸¡ëœ 4ê°œ ì½”ë„ˆ ì˜¤í”„ì…‹ (B,2,2,2)
            else:
                four_pred = torch.zeros((flow_gt.shape[0], 2, 2, 2))

            # ==================== ğŸ” ì²« ë°°ì¹˜ ë””ë²„ê¹… ====================
            if i_batch == 0:
                print("\n" + "="*80)
                print("ğŸš¨ FIRST BATCH DIAGNOSIS")
                print("="*80)
                
                # Ground Truth 4ê°œì˜ ì½”ë„ˆì˜ flow ì¶”ì¶œ (ì—¬ê¸°ì„œ ë¨¼ì € ê³„ì‚°)
                flow_4cor = torch.zeros((flow_gt.shape[0], 2, 2, 2))
                flow_4cor[:, :, 0, 0] = flow_gt[:, :, 0, 0]      # ì¢Œìƒë‹¨
                flow_4cor[:, :, 0, 1] = flow_gt[:, :, 0, -1]     # ìš°ìƒë‹¨
                flow_4cor[:, :, 1, 0] = flow_gt[:, :, -1, 0]     # ì¢Œí•˜ë‹¨ 
                flow_4cor[:, :, 1, 1] = flow_gt[:, :, -1, -1]    # ìš°í•˜ë‹¨
                
                # ì˜ˆì¸¡ê°’ í™•ì¸
                print(f"\n[1] Predictions (first sample):")
                print(f"four_pred[0]:\n{four_pred[0]}")
                print(f"Prediction stats: min={four_pred.min():.2f}, max={four_pred.max():.2f}, mean={four_pred.mean():.2f}, std={four_pred.std():.2f}")
                
                # GT í™•ì¸
                print(f"\n[2] Ground Truth (first sample):")
                print(f"flow_4cor[0]:\n{flow_4cor[0]}")
                print(f"GT stats: min={flow_4cor.min():.2f}, max={flow_4cor.max():.2f}, mean={flow_4cor.mean():.2f}")
                
                # Alpha ê³„ì‚°
                original_pixel_size_m = 0.5
                database_actual_size_m = args.database_size * original_pixel_size_m
                alpha = database_actual_size_m / args.resize_width
                
                # MACE í™•ì¸ (ê°„ë‹¨ ê³„ì‚°)
                mace_temp = (flow_4cor - four_pred.cpu().detach()) ** 2
                mace_temp = ((mace_temp[:, 0, :, :] + mace_temp[:, 1, :, :]) ** 0.5)
                mace_temp_mean = torch.mean(torch.mean(mace_temp, dim=1), dim=1)
                
                print(f"\n[3] MACE Calculation:")
                print(f"mace_vec[0] (pixels): {mace_temp_mean[0]:.2f}")
                print(f"alpha: {alpha:.6f} m/px")
                print(f"mace_vec[0] (meters): {mace_temp_mean[0] * alpha:.2f}")
                
                # UTM ê±°ë¦¬
                utm_dist = torch.sqrt(
                    (query_utm[0,0,0] - database_utm[0,0,0])**2 + 
                    (query_utm[0,0,1] - database_utm[0,0,1])**2
                ).item()
                print(f"\n[4] UTM Distance: {utm_dist:.2f} m")
                
                # ì…ë ¥ ì´ë¯¸ì§€
                print(f"\n[5] Input Images:")
                print(f"img1 range: [{img1.min():.3f}, {img1.max():.3f}]")
                print(f"img2 range: [{img2.min():.3f}, {img2.max():.3f}]")
                
                # ì˜ˆì¸¡ì´ ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ”ì§€
                if torch.all(four_pred == 0):
                    print("\nâš ï¸  WARNING: All predictions are ZERO!")
                
                print("="*80 + "\n")
            # ==================== ì²« ë°°ì¹˜ ë””ë²„ê¹… ì¢…ë£Œ ====================

# ==================== ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œë³„ ì‹œê°í™” ====================
            if not args.identity:
                for b_idx in range(current_batch_size):
                    # ì‹¤ì œ ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                    actual_index = index[b_idx].item()
                    
                    # ì‹œê°í™” ë²”ìœ„ ì²´í¬
                    if actual_index < VIS_START_INDEX:
                        continue
                    if VIS_END_INDEX is not None and actual_index >= VIS_END_INDEX:
                        continue
                    
                    # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
                    q_img = img1[b_idx].permute(1, 2, 0).cpu().numpy()
                    d_img = img2[b_idx].permute(1, 2, 0).cpu().numpy()
                    # [0,1] ë²”ìœ„ â†’ [0,255] ë²”ìœ„ë¡œ ë³€í™˜
                    q_img = (q_img * 255).astype(np.uint8)
                    d_img = (d_img * 255).astype(np.uint8)

                    # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì €ì¥
                    h, w = q_img.shape[:2]
                    
                    # ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” í•´ìƒë„ (ì˜ˆ: 384x384)
                    S = int(args.resize_width)

                    # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                    q_small = cv2.resize(q_img, (S, S))
                    d_small = cv2.resize(d_img, (S, S))

                    # ì›ë³¸ 4ê°œ ì½”ë„ˆ ì¢Œí‘œ ì •ì˜ (SÃ—S ì´ë¯¸ì§€ ê¸°ì¤€)
                    four_point_org_single = torch.zeros((1, 2, 2, 2))
                    four_point_org_single[:, :, 0, 0] = torch.tensor([0, 0])            # ì¢Œìƒë‹¨
                    four_point_org_single[:, :, 0, 1] = torch.tensor([S - 1, 0])        # ìš°ìƒë‹¨
                    four_point_org_single[:, :, 1, 0] = torch.tensor([0, S - 1])        # ì¢Œí•˜ë‹¨
                    four_point_org_single[:, :, 1, 1] = torch.tensor([S - 1, S - 1])    # ìš°í•˜ë‹¨

                    # í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚°ì„ ìœ„í•œ ì  ì§‘í•© ìƒì„±
                    # src: ì›ë³¸ 4ê°œ ì½”ë„ˆ
                    src_pts = four_point_org_single.flatten(2).permute(0, 2, 1)[0].numpy().astype(np.float32)
                    # dst: ì˜ˆì¸¡ëœ ì˜¤í”„ì…‹ì„ ë”í•œ 4ê°œ ì½”ë„ˆ
                    dst_pts_pred  = (four_pred[b_idx].cpu().detach().unsqueeze(0) + four_point_org_single) \
                                .flatten(2).permute(0, 2, 1)[0].numpy().astype(np.float32)

                    # 4ì  í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ ê³„ì‚° ë° ì›Œí•‘
                    H_pred  = cv2.getPerspectiveTransform(src_pts, dst_pts_pred)
                    warped_pred  = cv2.warpPerspective(d_small, H_pred, (S, S))

                    ## ì•ŒíŒŒ ë¸”ë Œë”©ìœ¼ë¡œ ê²¹ì¹œ ì´ë¯¸ì§€ ìƒì„±
                    alpha_blend = 0.5
                    overlay_small = cv2.addWeighted(q_small, 1 - alpha_blend, warped_pred, alpha_blend, 0)
                    
                    # ========== GT í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° (ì´ˆë¡ìƒ‰ìœ¼ë¡œ í‘œì‹œ) ==========
                    # GT flowì—ì„œ 4ê°œ ì½”ë„ˆ ì¶”ì¶œ
                    flow_4cor_single = torch.zeros((1, 2, 2, 2))
                    flow_4cor_single[:, :, 0, 0] = flow_gt[b_idx, :, 0, 0]      # ì¢Œìƒë‹¨
                    flow_4cor_single[:, :, 0, 1] = flow_gt[b_idx, :, 0, -1]     # ìš°ìƒë‹¨
                    flow_4cor_single[:, :, 1, 0] = flow_gt[b_idx, :, -1, 0]     # ì¢Œí•˜ë‹¨ 
                    flow_4cor_single[:, :, 1, 1] = flow_gt[b_idx, :, -1, -1]    # ìš°í•˜ë‹¨
                    
                    dst_pts_gt = (flow_4cor_single + four_point_org_single) \
                                .flatten(2).permute(0, 2, 1)[0].numpy().astype(np.float32)

                    # GT í˜¸ëª¨ê·¸ë˜í”¼ë¡œ ì›Œí•‘
                    H_gt = cv2.getPerspectiveTransform(src_pts, dst_pts_gt)
                    warped_gt = cv2.warpPerspective(d_small, H_gt, (S, S))
                    
                    # GT ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚° (4ê°œ ì½”ë„ˆì˜ í‰ê· )
                    center_gt_x = int(np.mean(dst_pts_gt[:, 0]))
                    center_gt_y = int(np.mean(dst_pts_gt[:, 1]))

                    # ì˜ˆì¸¡ ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚° (4ê°œ ì½”ë„ˆì˜ í‰ê· )
                    center_pred_x = int(np.mean(dst_pts_pred[:, 0]))
                    center_pred_y = int(np.mean(dst_pts_pred[:, 1]))

                    # ========== ì˜ˆì¸¡, gt ì¤‘ì‹¬ì  ê·¸ë¦¬ê¸° ==========
                    # GT ì‚¬ê°í˜• (ì´ˆë¡ìƒ‰)
                    cv2.circle(overlay_small, (center_gt_x, center_gt_y), 5, (0, 255, 0), -1)
 
                    
                    # ì˜ˆì¸¡ ì¤‘ì‹¬ì  (ë¹¨ê°„ìƒ‰ ì )
                    cv2.circle(overlay_small, (center_pred_x, center_pred_y), 5, (255, 0, 0), -1)
                    # ========== ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„± ==========                    

                    # ì›ë³¸ í•´ìƒë„ë¡œ ì—…ìƒ˜í”Œí•˜ì—¬ ì‹œê°í™”
                    d_big = cv2.resize(d_small, (w, h))
                    overlay_big = cv2.resize(overlay_small, (w, h))

                    # Query | Database | Overlay í˜•íƒœë¡œ ë°°ì¹˜ 
                    vis3 = np.hstack([q_img, d_big, overlay_big])
                    
                    # ê²°ê³¼ ì €ì¥ (ì‹¤ì œ ì¸ë±ìŠ¤ë¡œ ì €ì¥)
                    save_dir = "outputs_NewYork_NY_trained_match_vp100/match_images"
                    os.makedirs(save_dir, exist_ok=True)
                    save_path = os.path.join(save_dir, f"match_{actual_index:05d}.png")
                    cv2.imwrite(save_path, cv2.cvtColor(vis3, cv2.COLOR_RGB2BGR))
                    
                    saved_vis_count += 1
# ==================== ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œë³„ ì‹œê°í™” ====================


            # ==================== ë©”íŠ¸ë¦­ ê³„ì‚° ====================
            # Ground Truth 4ê°œì˜ ì½”ë„ˆì˜ flow ì¶”ì¶œ
            flow_4cor = torch.zeros((flow_gt.shape[0], 2, 2, 2))
            flow_4cor[:, :, 0, 0] = flow_gt[:, :, 0, 0]      # ì¢Œìƒë‹¨
            flow_4cor[:, :, 0, 1] = flow_gt[:, :, 0, -1]     # ìš°ìƒë‹¨
            flow_4cor[:, :, 1, 0] = flow_gt[:, :, -1, 0]     # ì¢Œí•˜ë‹¨ 
            flow_4cor[:, :, 1, 1] = flow_gt[:, :, -1, -1]    # ìš°í•˜ë‹¨

            # Flow í¬ê¸° ê³„ì‚° (L2 norm)
            flow_ = (flow_4cor) ** 2
            flow_ = ((flow_[:, 0, :, :] + flow_[:, 1, :, :]) ** 0.5)
            flow_vec = torch.mean(torch.mean(flow_, dim=1), dim=1)

            # MACE ê³„ì‚° (ì˜ˆì¸¡ê³¼ GTì˜ ì°¨ì´)
            mace_ = (flow_4cor - four_pred.cpu().detach()) ** 2
            mace_ = ((mace_[:, 0, :, :] + mace_[:, 1, :, :]) ** 0.5)
            mace_vec = torch.mean(torch.mean(mace_, dim=1), dim=1)


# ==================== dataset ë§ˆë‹¤ ë°”ê¿”ì•¼ í•¨  ====================
# ì˜¬ë°”ë¥¸ mace êµ¬í•˜ê¸°  mace ë‚˜ì˜¨ê±° =x
# x *crop í•œ ì‚¬ì´ì¦ˆ * í•´ìƒë„ / resize_width 

            # ì˜¬ë°”ë¥¸ mace ì‹œë„
            # ì‹¤ì œ ë°ì´í„°ì…‹ì˜ í•´ìƒë„ ì •ë³´
            original_pixel_size_m = 0.5  # ì›ë³¸ ìœ„ì„±ì‚¬ì§„ 1í”½ì…€ = 0.5ë¯¸í„°

            # Databaseê°€ ì‹¤ì œë¡œ ì»¤ë²„í•˜ëŠ” ì˜ì—­
            database_actual_size_m = args.database_size * original_pixel_size_m  # ì œì£¼ ê¸°ì¤€ 294í”½ì…€ Ã— 0.5m/í”½ì…€ = 147ë¯¸í„°

            # ë¦¬ì‚¬ì´ì¦ˆ í›„ 1í”½ì…€ì´ ë‚˜íƒ€ë‚´ëŠ” ì‹¤ì œ ê±°ë¦¬
            alpha = database_actual_size_m / args.resize_width  # 147m / 384px â‰ˆ 0.383 m/px


# ==================== dataset ë§ˆë‹¤ ë°”ê¿”ì•¼ í•¨  ====================


            # MACEë¥¼ ë¯¸í„°ë¡œ ë³€í™˜
            mace_vec = mace_vec * alpha  # í”½ì…€ â†’ ë¯¸í„°



            # ëˆ„ì 
            total_mace = torch.cat([total_mace, mace_vec], dim=0)
            final_mace = torch.mean(total_mace).item()
            total_flow = torch.cat([total_flow, flow_vec], dim=0)
            final_flow = torch.mean(total_flow).item()

            # ==================== Center Error (CE) ê³„ì‚° ====================
            # ì¤‘ì‹¬ì  ì˜¤í”„ì…‹ ê³„ì‚°ì„ ìœ„í•œ ì½”ë„ˆ ì •ì˜
            four_point_org_single_w = torch.zeros((1, 2, 2, 2))
            four_point_org_single_w[:, :, 0, 0] = torch.Tensor([0, 0])
            four_point_org_single_w[:, :, 0, 1] = torch.Tensor([args.resize_width - 1, 0])
            four_point_org_single_w[:, :, 1, 0] = torch.Tensor([0, args.resize_width - 1])
            four_point_org_single_w[:, :, 1, 1] = torch.Tensor([args.resize_width - 1, args.resize_width - 1])

            # ì˜ˆì¸¡ ë° GT ì½”ë„ˆ ì¢Œí‘œ ê³„ì‚°
            four_point_1 = four_pred.cpu().detach() + four_point_org_single_w
            four_point_org = four_point_org_single_w.repeat(four_point_1.shape[0], 1, 1, 1).flatten(2).permute(0, 2, 1).contiguous()
            four_point_1 = four_point_1.flatten(2).permute(0, 2, 1).contiguous()
            four_point_gt = flow_4cor.cpu().detach() + four_point_org_single_w
            four_point_gt = four_point_gt.flatten(2).permute(0, 2, 1).contiguous()

            # ì˜ˆì¸¡ í˜¸ëª¨ê·¸ë˜í”¼ë¡œ ì¤‘ì‹¬ì  ë³€í™˜
            H_k = tgm.get_perspective_transform(four_point_org, four_point_1)
            center_T = torch.tensor([args.resize_width / 2 - 0.5, args.resize_width / 2 - 0.5, 1]).unsqueeze(1).unsqueeze(0).repeat(H_k.shape[0], 1, 1)
            w_ = torch.bmm(H_k, center_T).squeeze(2)
            center_pred_offset = w_[:, :2] / w_[:, 2].unsqueeze(1) - center_T[:, :2].squeeze(2)

            # GT í˜¸ëª¨ê·¸ë˜í”¼ë¡œ ì¤‘ì‹¬ì  ë³€í™˜
            H_gt = tgm.get_perspective_transform(four_point_org, four_point_gt)
            w_gt = torch.bmm(H_gt, center_T).squeeze(2)
            center_gt_offset = w_gt[:, :2] / w_gt[:, 2].unsqueeze(1) - center_T[:, :2].squeeze(2)

            # CE ê³„ì‚° (ì˜ˆì¸¡ ì¤‘ì‹¬ê³¼ GT ì¤‘ì‹¬ì˜ ê±°ë¦¬)
            ce_ = (center_pred_offset - center_gt_offset) ** 2
            ce_ = ((ce_[:, 0] + ce_[:, 1]) ** 0.5)
            ce_vec = ce_


            # CEë¥¼ ë¯¸í„°ë¡œ ë³€í™˜
            ce_meters = ce_vec * alpha  # í”½ì…€ â†’ ë¯¸í„°


            total_ce = torch.cat([total_ce, ce_meters], dim=0)
            final_ce = torch.mean(total_ce).item()
            # ==================== Center Error (CE) ê³„ì‚° ì¢…ë£Œ====================



            # ==================== Recall  ê³„ì‚° ====================
            # CEê°€ íŠ¹ì • threshold ì´í•˜ì´ë©´ correct predictionìœ¼ë¡œ ê°„ì£¼
            recall_threshold_25 = 25.0  # 25 ë¯¸í„°
            correct_in_batch_25 = torch.sum(ce_meters <= recall_threshold_25).item()
            correct_predictions_25 += correct_in_batch_25
            total_predictions_25 += len(ce_vec)

            recall_threshold_10 = 10.0  # 10 ë¯¸í„°
            correct_in_batch_10 = torch.sum(ce_meters <= recall_threshold_10).item()
            correct_predictions_10 += correct_in_batch_10
            total_predictions_10 += len(ce_vec)

            recall_threshold_1 = 1.0  # 1 ë¯¸í„°
            correct_in_batch_1 = torch.sum(ce_meters <= recall_threshold_1).item()
            correct_predictions_1 += correct_in_batch_1
            total_predictions_1 += len(ce_vec)

            # ==================== Recall  ê³„ì‚° ì¢…ë£Œ ====================
        
        # ì²˜ë¦¬ëœ ìƒ˜í”Œ ìˆ˜ ì—…ë°ì´íŠ¸
        processed_samples += current_batch_size
    
                
    # ë£¨í”„ ì¢…ë£Œ í›„ Recall ìµœì¢… ê³„ì‚°
    recall_at_25 = correct_predictions_25 / total_predictions_25 if total_predictions_25 > 0 else 0.0
    recall_at_10 = correct_predictions_10 / total_predictions_10 if total_predictions_10 > 0 else 0.0
    recall_at_1 = correct_predictions_1 / total_predictions_1 if total_predictions_1 > 0 else 0.0

    # ==================== í‰ê°€ ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥ ====================
    if not args.train_ue_method == "train_only_ue_raw_input":
        print(f"\n{'='*60}")
        print(f"FINAL EVALUATION RESULTS")
        print(f"{'='*60}")
        print(f"MACE Metric: {final_mace:.4f} m")
        print(f'CE Metric: {final_ce:.4f} m')
        print(f'Recall@1m:  {recall_at_1:.4f} ({correct_predictions_1}/{total_predictions_1})')
        print(f'Recall@10m: {recall_at_10:.4f} ({correct_predictions_10}/{total_predictions_10})')
        print(f'Recall@25m: {recall_at_25:.4f} ({correct_predictions_25}/{total_predictions_25})') 
        print(f"{'='*60}\n")

        if wandb_log:
            wandb.log({"test_mace": final_mace})
            wandb.log({"test_ce": final_ce})
            wandb.log({"test_recall_at_1": recall_at_1})
            wandb.log({"test_recall_at_10": recall_at_10})
            wandb.log({"test_recall_at_25": recall_at_25})
            
    # Uncertainty ê´€ë ¨ ì‹œê°í™”
    if args.use_ue:
        mace_conf_list = np.array(mace_conf_list)
        
        # MACE vs Confidence ì‚°ì ë„
        plt.figure()
        plt.scatter(mace_conf_list[:, 0], mace_conf_list[:, 1], s=1)
        x = np.linspace(0, 100, 400)
        y = np.exp(args.ue_alpha * x)
        plt.plot(x, y, label='f(x) = exp(-0.1x)', color='red')
        plt.legend()
        plt.savefig(args.save_dir + f'/final_conf.png')
        plt.close()
        
        # Confidence íˆìŠ¤í† ê·¸ë¨
        plt.figure()
        n, bins, patches = plt.hist(x=mace_conf_list[:, 1], bins=np.linspace(0, 1, 20))
        logging.info(n)
        plt.close()
    
            
    # ê²°ê³¼ë¥¼ .mat ë° .npy íŒŒì¼ë¡œ ì €ì¥
    io.savemat(args.save_dir + '/resmat', {'matrix': total_mace.numpy()})
    np.save(args.save_dir + '/resnpy.npy', total_mace.numpy())
    io.savemat(args.save_dir + '/flowmat', {'matrix': total_flow.numpy()})
    np.save(args.save_dir + '/flownpy.npy', total_flow.numpy())
    
    # íˆìŠ¤í† ê·¸ë¨ í”Œë¡¯ ìƒì„±
    plot_hist_helper(args.save_dir)

    # ==================== ë©”íŠ¸ë¦­ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ====================
    os.makedirs("outputs_NewYork_NY_trained_match_vp100", exist_ok=True)
    metrics_path = os.path.join("outputs_NewYork_NY_trained_match_vp100", "metrics.txt")

    # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    end_time = datetime.now()
    elapsed_time = end_time - start_time
    elapsed_str = str(elapsed_time).split(".")[0]


    with open(metrics_path, "w") as f:
        f.write("=== Evaluation Results ===\n")
        f.write(f"MACE: {final_mace:.6f}\n")
        f.write(f"CE:   {final_ce:.6f}\n")
        f.write(f"Recall 10:   {recall_at_10:.6f}\n\n")
        f.write(f"Recall 25:   {recall_at_25:.6f}\n\n")
        f.write(f"Recall 1:   {recall_at_1:.6f}\n\n")

        f.write("=== Data Augmentation ===\n")
        f.write(f"Augment Type     : {args.augment}\n")
        f.write(f"Rotate Max       : {args.rotate_max:.2f} rad ({np.degrees(args.rotate_max):.2f} deg)\n")
        f.write(f"Resize Max       : {args.resize_max}\n")
        f.write(f"Perspective Max  : {args.perspective_max}\n\n")


        f.write("=== Dataset Info ===\n")
        f.write(f"Dataset Name     : {args.dataset_name}\n")
        f.write(f"Database Size    : {args.database_size}\n")
        f.write(f"Positive Thres   : {args.val_positive_dist_threshold}\n")
        f.write(f"Correlation Lvl  : {args.corr_level}\n")
        f.write(f"Generate Pairs   : {args.generate_test_pairs}\n\n")

        f.write("=== Runtime Settings ===\n")
        f.write(f"Batch Size       : {args.batch_size}\n")
        f.write(f"Num Workers      : {args.num_workers}\n")
        f.write(f"Lev0             : {args.lev0}\n")
        f.write(f"Start Time       : {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"End Time         : {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Elapsed Time     : {elapsed_str}\n\n")

        f.write("=== Model Info ===\n")
        f.write(f"Eval Model       : {args.eval_model}\n")
        f.write(f"Two Stages       : {args.two_stages}\n\n")

        f.write("=== System Info ===\n")
        f.write(f"Python Version   : {platform.python_version()}\n")
        f.write(f"PyTorch Version  : {torch.__version__}\n")
        f.write(f"CUDA Version     : {torch.version.cuda}\n")
        f.write(f"GPU              : NVIDIA Tesla V100\n")

        f.write("=== Extra ===\n")
        f.write(f"Flow Mean: {final_flow:.6f}\n")
        f.write(f"Total Samples Evaluated: {processed_samples}\n")
        f.write(f"Total Visualizations Saved: {saved_vis_count}\n\n")


    print(f"[INFO] Metrics saved at {metrics_path}")
    print(f"[INFO] Evaluated {processed_samples} samples, saved {saved_vis_count} visualizations")



if __name__ == '__main__':
    args = parser.parse_arguments()
    start_time = datetime.now()
    if args.identity:
        pass
    else:
        args.save_dir = join(
        "test",
        args.save_dir,
        args.eval_model.split("/")[-2] if args.eval_model is not None else args.eval_model_ue.split("/")[-2],
        f"{args.dataset_name}-{start_time.strftime('%Y-%m-%d_%H-%M-%S')}",
        )
        commons.setup_logging(args.save_dir, console='info')
    setup_seed(0)
    logging.debug(args)
    wandb_log = False
    if wandb_log:
        wandb.init(project="STHN-eval", entity="aeaaea898-yonsei-university", config=vars(args))
    test(args, wandb_log)



    """
    python3 local_pipeline/t_evaluate_1_image_matrix.py   --datasets_folder t_datasets     --dataset_name 2276_datasets     --eval_model pretrained_models/1536_two_stages/STHN.pth     --val_positive_dist_threshold 512     --lev0     --database_size 1536     --corr_level 4     --test     --num_workers 0     --batch_size 1  
    python3 local_pipeline/t_evaluate_1_image_matrix.py   --datasets_folder dataset_jeju   --dataset_name jeju   --eval_model pretrained_models/1536_two_stages/STHN.pth   --val_positive_dist_threshold 50   --lev0   --database_size 294   --corr_level 4   --test   --num_workers 0   --batch_size 1  --batch_size 1     

    """


    """
    python3 local_pipeline/t_evaluate_1_image_matrix.py   --datasets_folder datasets_jeju   --dataset_name jeju   --eval_model trained/1000_STHN.pth   --val_positive_dist_threshold 100   --lev0   --database_size 294   --corr_level 4   --test   --num_workers 0   --batch_size 1                      

    """